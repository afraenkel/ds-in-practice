
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Information Extraction from Text &#8212; The Practice of Data Science</title>
    
  <link rel="stylesheet" href="../../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/language_data.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Introduction to Features" href="../09/introduction.html" />
    <link rel="prev" title="Text Data" href="patterns.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../index.html">
  
  <img src="../../_static/toolbox.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">The Practice of Data Science</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction.html">
   Data Science in Practice
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Understanding Data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../01/introduction.html">
   Introduction to Data Science
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../01/what-is-data-science.html">
     What is Data Science?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/scientific-method.html">
     The Scientific Method
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../01/data-science-example.html">
     A Data Science Example
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../02/introduction.html">
   The Basics of Tabular Data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../02/tabular-data.html">
     Tabular Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/tabular-data.html#tables-in-python-using-pandas">
     Tables in python, using Pandas.
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/methods.html">
     Table Methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../02/data-types.html">
     Data Types and Performance
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../03/introduction.html">
   Querying and Describing Data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../03/selecting-data.html">
     Selecting Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/kinds-of-data.html">
     Kinds of Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/categorical-distributions.html">
     Categorical Distributions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../03/quantitative-distributions.html">
     Quantitative Distributions
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../04/introduction.html">
   Understanding Assumptions and Data Cleaning
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../04/modifying-dataframes.html">
     Modifying DataFrames
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/cleaning.html">
     Cleaning Messy Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../04/eda.html">
     Exploratory Data Analysis
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../05/introduction.html">
   Aggregation and Extension of Data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../05/grouping.html">
     Data Granularity
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/understanding-aggregations.html">
     Understanding Aggregations
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/appending-data.html">
     Combining Data (Observations)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/joining-data.html">
     Combining Data: Attributes
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/joining-data.html#combining-different-measurements-over-the-same-individuals">
     Combining different measurements over the same individuals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/permutation-tests.html">
     Permutation Tests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../05/eda-2.html">
     Exploratory Data Analysis II
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../06/introduction.html">
   Missing Data
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../06/defining-missing.html">
     Definitions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/identifying-missing.html">
     Identifying Missing Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/handling-missing-data.html">
     Handling Missing Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/single-valued-imputation.html">
     Single-Valued Imputation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../06/probabilistic-imputation.html">
     Probabilistic Imputation
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Collecting Data
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../07/introduction.html">
   Data Collection
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../07/existing-data.html">
     Using Existing Data
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/requests.html">
     HTTP Requests
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../07/html.html">
     Parsing HTML
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 current active collapsible-parent">
  <a class="reference internal" href="introduction.html">
   Information Extaction
  </a>
  <ul class="current collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="patterns.html">
     Text Processing
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Natural Language Processing
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../09/introduction.html">
   Introduction to Features
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../09/features.html">
     Feature Engineering
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../09/data-pipelines.html">
     Data Pipelines
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Modeling With Data
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../10/introduction.html">
   Modeling Basics
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../10/intro-modeling.html">
     Introduction to Statistical Models
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../10/model-building.html">
     Building Modeling Pipelines
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../11/introduction.html">
   Bias and Variance
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../11/fitting-inference.html">
     Model Quality (Inference)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/fitting-prediction.html">
     Model Quality (Prediction)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/cross-validation.html">
     Cross Validation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../11/parameter-search.html">
     Parameter Search
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
 <li class="toctree-l1 collapsible-parent">
  <a class="reference internal" href="../12/introduction.html">
   Evaluating Models; Fairness
  </a>
  <ul class="collapse-ul">
   <li class="toctree-l2">
    <a class="reference internal" href="../12/eval.html">
     Evaluation metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/parity.html">
     Parity Measures
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../12/fairness.html">
     Fairness in Machine Learning
    </a>
   </li>
  </ul>
  <i class="fas fa-chevron-down">
  </i>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/content/08/nlp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/afraenkel/ds-in-practice/master?urlpath=tree/book/content/08/nlp.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-limits-of-pattern-matching">
   The Limits of Pattern Matching
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measuring-similarity-between-text">
   Measuring Similarity between Text
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-bag-of-words-model">
     The “Bag of Words” model
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#measures-of-relevancy">
   Measures of Relevancy
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#term-frequency-inverse-document-frequency-tf-idf">
     Term Frequency, Inverse Document Frequency (TF-IDF)
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="information-extraction-from-text">
<h1>Information Extraction from Text<a class="headerlink" href="#information-extraction-from-text" title="Permalink to this headline">¶</a></h1>
<hr class="docutils" />
<div class="section" id="the-limits-of-pattern-matching">
<h2>The Limits of Pattern Matching<a class="headerlink" href="#the-limits-of-pattern-matching" title="Permalink to this headline">¶</a></h2>
<p>Pattern matching is an information extraction on technique on text that offer a way to introduce oneself to raw text. However, pattern matching has its limits:</p>
<ul class="simple">
<li><p>How are common patterns proposed and found?</p></li>
<li><p>The ad-hoc development and exploration of information extraction with patterns does not scale to large amounts of text.</p></li>
<li><p>Assessing the efficacy of a pattern to effectively extract information does not scale well past visual inspection. When an large-scale analysis is done, it’s time consuming and likely not applicable to similar patterns.</p></li>
</ul>
<p>To move beyond these limits, one must approach information extraction from text more methodically, using a quantitative approach borrowed from math and statistics.</p>
</div>
<div class="section" id="measuring-similarity-between-text">
<h2>Measuring Similarity between Text<a class="headerlink" href="#measuring-similarity-between-text" title="Permalink to this headline">¶</a></h2>
<p>Given two snippets of text, are they similar? At heart, this question is asking for <em>a distance measure</em> between words and phrases. While there are many such measures of distance, each capturing different aspects of the information in text, they all require a common setup: how should the text be embedded into a quantitative (e.g. Euclidean) space?</p>
<div class="section" id="the-bag-of-words-model">
<h3>The “Bag of Words” model<a class="headerlink" href="#the-bag-of-words-model" title="Permalink to this headline">¶</a></h3>
<p>Consider the following listings for housing rentals:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>phrase</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>a two bedroom apartment with washer and dryer</p></td>
</tr>
<tr class="row-odd"><td><p>a two bedroom house with a washer hookup</p></td>
</tr>
<tr class="row-even"><td><p>a three bedroom house with a fireplace</p></td>
</tr>
</tbody>
</table>
<p>Since a listing is made up of a collection of amenities, two listings might be considered similar if they share similar words. That is:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">two</span> <span class="pre">bedroom</span> <span class="pre">apartment</span> <span class="pre">with</span> <span class="pre">washer</span> <span class="pre">and</span> <span class="pre">dryer</span></code> and</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">two</span> <span class="pre">bedroom</span> <span class="pre">house</span> <span class="pre">with</span> <span class="pre">a</span> <span class="pre">washer</span> <span class="pre">hookup</span></code></p></li>
</ul>
<p>share five words (<code class="docutils literal notranslate"><span class="pre">a</span></code>, <code class="docutils literal notranslate"><span class="pre">two</span></code>, <code class="docutils literal notranslate"><span class="pre">bedroom</span></code>, <code class="docutils literal notranslate"><span class="pre">with</span></code>, <code class="docutils literal notranslate"><span class="pre">washer</span></code>). This matching can be turned into a measure of similarity in a number of ways:</p>
<ul class="simple">
<li><p>Using the raw number itself as a measure, where larger is more similar (e.g. the similarity is 5).</p></li>
<li><p>Using the proportion of possible matches, where 1 is the most similar (e.g. 5/7 words were matches).</p></li>
<li><p>Computing the empirical distribution of each phrase and using the Total Variation Distance (TVD).</p></li>
</ul>
<p><em>Remark:</em> The first measure is not normalized, which is may be a good property. The likelihood that two very long phrases are similar is much smaller than two short phrases.</p>
<p>The ‘Bag of Words’ model sets up this notion of similarity by embedding the words into a <em>vector space</em>. This vector space embedding allows one to easily compute different notions of similar and understand the distribution of words among the phrases in a dataset.</p>
<p>The <strong>Bag of Words embedding</strong> of a list of phrases is representation of the counts of words in each phrase in vector space whose basis consists of all words appearing in the dataset.</p>
<p><strong>Example:</strong> The Bag of Words embedding of the three row table of housing listings transforms the phrases into a 12-dimensional vector space:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>a</p></th>
<th class="head"><p>two</p></th>
<th class="head"><p>three</p></th>
<th class="head"><p>bedroom</p></th>
<th class="head"><p>apartment</p></th>
<th class="head"><p>house</p></th>
<th class="head"><p>with</p></th>
<th class="head"><p>washer</p></th>
<th class="head"><p>hookup</p></th>
<th class="head"><p>and</p></th>
<th class="head"><p>dryer</p></th>
<th class="head"><p>fireplace</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>2</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
<td><p>1</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>0</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p><em>Remark:</em> Notice that the bag-of-words embedding is nothing but systematically pattern matching: for each word in the dataset, count the number of occurrences of each words in each phrase. However, the Bag of Words embedding doesn’t know anything about the <em>meaning</em> of each words. The embedding works under the assumption that two phrases are similar if they share many of the same words.</p>
<p>Using a Bag of Words embedding, the <strong>similarity</strong> of two phrases can be measured using notions of similarity in the Bag of Words vector space. Under the Bag of Word embedding:</p>
<ul class="simple">
<li><p>The similarity of two phrases is proportional to the dot product of the Bag of Words vectors.</p></li>
<li><p>The similarity of two phrases is given by the <em>cosine similarity</em> of the Bag of Words vectors:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[dist(v, w) = 1 - \cos(\theta) = 1 - \frac{v \cdot w}{|v||w|}\]</div>
<p><strong>Example:</strong> In the above housing listings, which listings are most similar under the Bag of Words model?</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p>phrase pair</p></th>
<th class="head"><p>dot product</p></th>
<th class="head"><p>cosine similarity</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0,1</p></td>
<td><p>2+1+0+1+0+0+1+1+0+0+0+0 = 6</p></td>
<td><p>0.33</p></td>
</tr>
<tr class="row-odd"><td><p>0,2</p></td>
<td><p>2+0+0+1+0+1+1+0+0+0+0+0 = 5</p></td>
<td><p>0.41</p></td>
</tr>
<tr class="row-even"><td><p>1,2</p></td>
<td><p>4+0+0+1+0+1+1+0+0+0+0+0 = 7</p></td>
<td><p>0.26</p></td>
</tr>
</tbody>
</table>
<p>As measured by the cosine similarity, the most similar phrase pair is the middle and last phrases.</p>
<p><em>Remark:</em> The Bag of Words model has downsides, already seen in this example:</p>
<ul class="simple">
<li><p>The model treats all words as <em>equally important</em>. For exaample, the word ‘a’ and the word ‘apartment’ are given equal weight.</p></li>
<li><p>The model treats words without context. The phrases ‘I own a dog’ and ‘I don’t own a dog’ are similar in the bag of words model.</p></li>
</ul>
<p>However, the perspective of the Bag of Words model is powerful. These downsides can be handled with straightforward improvements and modifications.</p>
</div>
</div>
<div class="section" id="measures-of-relevancy">
<h2>Measures of Relevancy<a class="headerlink" href="#measures-of-relevancy" title="Permalink to this headline">¶</a></h2>
<p>A shortcoming of the naive Bag of Words model is that it treats every words equally. This treatment can cause two phrases with similar content to appear dissimilar because of ‘superfluous’ words. What are ways to extract ‘the most relevant’ words from a phrase?</p>
<div class="section" id="term-frequency-inverse-document-frequency-tf-idf">
<h3>Term Frequency, Inverse Document Frequency (TF-IDF)<a class="headerlink" href="#term-frequency-inverse-document-frequency-tf-idf" title="Permalink to this headline">¶</a></h3>
<p>An intuitive heuristic for extracting the most relevant term of a phrase is <em>Term Frequency, Inverse Document Frequency</em> or TF-IDF. This method attempts to answer the question “how much does a given word summarize a phrase?”.  TF-IDF attempts to balance the importance of a word in a given document with the uniqueness the word has to the document.</p>
<p>Suppose a dataset consists of a <em>collection of documents</em> <span class="math notranslate nohighlight">\(D\)</span>.</p>
<ul class="simple">
<li><p>The <em>term frequency</em> of a word <span class="math notranslate nohighlight">\(t\)</span> in a document <span class="math notranslate nohighlight">\(d\)</span>, denoted <span class="math notranslate nohighlight">\({\rm tf}(t,d)\)</span>, is the likelihood of the term appearing in the document:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[{\rm tf}(t, d) = \frac{\rm{number\: of\: times\: t\: appears\: in\: document\: d}}{\rm{total\: number\: of\: terms\: in\: document\: d}} \]</div>
<ul class="simple">
<li><p>The <em>inverse document frequency</em> of a word <span class="math notranslate nohighlight">\(t\)</span> in a collection of documents <span class="math notranslate nohighlight">\(D\)</span>, denoted <span class="math notranslate nohighlight">\({\rm idf}(t,d)\)</span> is:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[{\rm idf}(t) = \log\left(\frac{\rm{total\: number\: of\: documents}}{\rm{number\: of\: documents\: in\: which\: t\: appears}}\right)\]</div>
<ul class="simple">
<li><p>The <em>tf-idf</em> of a term <span class="math notranslate nohighlight">\(t\)</span> in document <span class="math notranslate nohighlight">\(d\)</span> is given by the product:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[{\rm tfidf}(t,d) = {\rm tf}(t,d) \cdot {\rm idf}(t)\]</div>
<p><em>Remark:</em> There are different, related, ways of computing this quantity. As this method is a heuristic, there isn’t a ‘correct’ formula with a probabilistic interpretation.</p>
<p>Notice that if a term appears in <em>every</em> document in the collection, the <span class="math notranslate nohighlight">\({\rm idf(t, d)}\)</span> is zero. This fits the intuition that very common words should not be considered relevant to the information contained in a document.</p>
<p><strong>Example:</strong> The TF-IDF of the word <code class="docutils literal notranslate"><span class="pre">two</span></code> in the first apartment listing is computed as follows:</p>
<div class="math notranslate nohighlight">
\[{\rm tf}(\texttt{two}, \texttt{listing0}) = \frac{1}{8}\]</div>
<div class="math notranslate nohighlight">
\[{\rm idf}(\texttt{two}) = \log(\frac{3}{2})\]</div>
<div class="math notranslate nohighlight">
\[{\rm tf}(\texttt{two}, \texttt{listing0})\cdot {\rm idf}(\texttt{two}) = \frac{1}{8}\log(\frac{3}{2})\]</div>
<p>This quantity naturally defines the most relevant words for a given document: the term with the highest TF-IDF for a given document <em>best summarizes</em> the document.</p>
<p><strong>Example:</strong> Computing the most relevant term for each listing is illustrated in the following code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">apts</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>phrase</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>a two bedroom apartment with washer and dryer</td>
    </tr>
    <tr>
      <th>1</th>
      <td>a two bedroom house with a washer hookup</td>
    </tr>
    <tr>
      <th>2</th>
      <td>a three bedroom house with a fireplace</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>While slower than leveraging optimized libraries, the Bag of Words embedding can be easily implemented with Pandas:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bow</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">apts</span><span class="p">[</span><span class="s1">&#39;phrase&#39;</span><span class="p">]</span>
    <span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">value_counts</span><span class="p">())</span>
<span class="p">)</span>
<span class="n">bow</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>washer</th>
      <th>with</th>
      <th>apartment</th>
      <th>two</th>
      <th>a</th>
      <th>and</th>
      <th>dryer</th>
      <th>bedroom</th>
      <th>hookup</th>
      <th>house</th>
      <th>three</th>
      <th>fireplace</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The term frequencies of each word, in each document, is represented in a matrix labeled by words and document number. Each word in a given document is part of an empirical distribution for that document:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">term_frequencies</span> <span class="o">=</span> <span class="n">bow</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span> <span class="o">/</span> <span class="n">x</span><span class="o">.</span><span class="n">sum</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">term_frequencies</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>washer</th>
      <th>with</th>
      <th>apartment</th>
      <th>two</th>
      <th>a</th>
      <th>and</th>
      <th>dryer</th>
      <th>bedroom</th>
      <th>hookup</th>
      <th>house</th>
      <th>three</th>
      <th>fireplace</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.125</td>
      <td>0.125000</td>
      <td>0.125</td>
      <td>0.125</td>
      <td>0.125000</td>
      <td>0.125</td>
      <td>0.125</td>
      <td>0.125000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.125</td>
      <td>0.125000</td>
      <td>NaN</td>
      <td>0.125</td>
      <td>0.250000</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.125000</td>
      <td>0.125</td>
      <td>0.125000</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>0.142857</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.285714</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.142857</td>
      <td>NaN</td>
      <td>0.142857</td>
      <td>0.142857</td>
      <td>0.142857</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The inverse document frequency is calculated using a straightforward count of non-null entries:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tot</span> <span class="o">=</span> <span class="n">bow</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">inverse_document_frequencies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">tot</span> <span class="o">/</span> <span class="n">bow</span><span class="o">.</span><span class="n">count</span><span class="p">())</span>
<span class="n">inverse_document_frequencies</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>washer       0.405465
with         0.000000
apartment    1.098612
               ...   
house        0.405465
three        1.098612
fireplace    1.098612
Length: 12, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>The resulting tfidf matrix represents the term frequency, inverse document of frequency of every term in every document:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf</span> <span class="o">=</span> <span class="n">term_frequencies</span> <span class="o">*</span> <span class="n">inverse_document_frequencies</span>
<span class="n">tfidf</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>washer</th>
      <th>with</th>
      <th>apartment</th>
      <th>two</th>
      <th>a</th>
      <th>and</th>
      <th>dryer</th>
      <th>bedroom</th>
      <th>hookup</th>
      <th>house</th>
      <th>three</th>
      <th>fireplace</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.050683</td>
      <td>0.0</td>
      <td>0.137327</td>
      <td>0.050683</td>
      <td>0.0</td>
      <td>0.137327</td>
      <td>0.137327</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.050683</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.050683</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>0.137327</td>
      <td>0.050683</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>2</th>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>0.057924</td>
      <td>0.156945</td>
      <td>0.156945</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>The most relevant word in each document corresponds to the word with the largest tfidf in that document:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tfidf</span><span class="o">.</span><span class="n">idxmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0    apartment
1       hookup
2        three
dtype: object
</pre></div>
</div>
</div>
</div>
<p><em>Remark:</em> Why are these words good summaries of each listing? In what ways are they <em>not</em> good summaries?</p>
<p><em>Remark:</em> These words were not the only correct answers; search for ties in the table.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./content/08"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="patterns.html" title="previous page">Text Data</a>
    <a class='right-next' id="next-link" href="../09/introduction.html" title="next page">Introduction to Features</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Aaron Fraenkel<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>